{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask.dataframe as dd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_headers = pd.read_csv('../data/raw/acquia_samples/scripts-headers/person-headers.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_columns = person_headers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_headers = pd.read_csv('../data/raw/acquia_samples/scripts-headers/event-headers.txt', delimiter='\\t')\n",
    "event_columns = event_headers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch_headers = pd.read_csv('../data/raw/acquia_samples/scripts-headers/touch_headers.txt', delimiter='\\t')\n",
    "touch_columns = touch_headers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_ranking_headers = pd.read_csv('../data/raw/acquia_samples/scripts-headers/person_ranking.tsv',\n",
    "                                     delimiter='\\t')\n",
    "person_ranking_columns = person_ranking_headers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_ranking_item_headers = pd.read_csv('../data/raw/acquia_samples/scripts-headers/person_ranking_item.tsv', \n",
    "                                          delimiter='\\t')\n",
    "person_ranking_item_columns = person_ranking_item_headers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_ranking_summary_headers = pd.read_csv('../data/raw/acquia_samples/scripts-headers/person_ranking_summary.tsv', \n",
    "                                          delimiter='\\t')\n",
    "person_ranking_summary_columns = person_ranking_summary_headers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_ranking_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_ranking_summary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "person_ranking_summary_headers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_identifier = dd.read_csv('Z:\\\\person_identifier.tsv', delimiter='\\t', \n",
    "                                names=['person_id', 'customer_id', 'identifier',\n",
    "                                       'identifier_type', '?', 'active', 'last_modified',\n",
    "                                       'db_last_modified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = dd.read_csv('Z:\\\\person.tsv', delimiter='\\t', \n",
    "                                names=person_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some columns look like floats at first because they are all NA, though they are strings (utm_...)\n",
    "# and dma_code looks like an int at first but has NA\n",
    "# for these we need to specify the type to read correctly\n",
    "touch = dd.read_csv('Z:\\\\touch.tsv', delimiter='\\t', encoding='utf-8',\n",
    "                    dtype={'utm_medium':str, 'utm_terms':str, 'utm_content':str, 'utm_name':str, 'url_domain':str,\n",
    "                          'dma_code':str,'customer_id': 'object',\n",
    "                                           'tbd': 'object',\n",
    "                                       'touch_duration.1': 'object'},\n",
    "                    assume_missing=True,\n",
    "                    names=touch_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(touch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('Z:\\\\touch.tsv', 'r') as f:\n",
    "    for i in range(1000000):\n",
    "        l = f.readline()\n",
    "        if i % 10000 == 0:\n",
    "            print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "even with encoding set to utf-8, we quickly see issues. For instance, a date falls on the field tbd. That date is 2019-03-04 01:54:30.000000. Could we find the lines around it and see if there's anything weird?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('Z:\\\\touch.tsv', 'r', encoding='utf-8') as f:\n",
    "    for i in range(200000):\n",
    "        l = f.readline()\n",
    "        if i % 10000 == 0:\n",
    "            print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Z:\\\\touch.tsv', 'r', encoding='utf-8') as f:\n",
    "    for i in range(160000):\n",
    "        l = f.readline()\n",
    "        if i>150000 and i % 1000 == 0:\n",
    "            print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Z:\\\\touch.tsv', 'r', encoding='utf-8') as f:\n",
    "    for i in range(10000000):\n",
    "        l = f.readline()\n",
    "        n_tabs = l.count('\\t')\n",
    "        if n_tabs != 58:\n",
    "            print('Line %i has %i tabs:' % (i, n_tabs))\n",
    "            print(repr(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I think ^ is _very_ interesting!\n",
    "\n",
    "There are essentially two problems:\n",
    "\n",
    "1) Some fields have \\n or \\t inside quotes. That should be easy to handle!\n",
    "\n",
    "2) Some instances of the thirtieth field, whatever it is, have \\n. That seems to me harder to completely fix, and we may end up with those lines broken in two...\n",
    "\n",
    "Update after the fact: I just fixed lines by hand - mostly deleted the extra lines after some fields. Did this by printing as above and then jumping to the affected line on 010Editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch_sample = pd.read_csv('../data/raw/acquia_samples/updated_data/touch.tsv', delimiter='\\t',\n",
    "                           dtype={'utm_medium':str, 'utm_terms':str, 'utm_content':str, 'utm_name':str, 'url_domain':str,\n",
    "                                  'dma_code':str},\n",
    "                           parse_dates=['touch_date', 'db_last_modified_date', 'db_last_modified_date.1'],\n",
    "                           names=touch_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_user = touch_sample.person_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are very few 1s, even in the sample data, which is surprising. But actually it's not: many touches get duplicated, somehow. See, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "touch_sample[touch_sample.person_id == 2066689106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three of these four are the same. So one task is to deduplicate these touches. To preserve all the data we should try to do this in a smart way, eg get the maximum duration, ignore NaN in favor of rows with that data, etc. For now I will not try to do this in a smart way -- let's try to keep just one of the rows, whichever it is.\n",
    "\n",
    "TODO: make this better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(touch_sample.touch_date.iloc[2782]-touch_sample.touch_date.iloc[2769])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch_sample_person_ids = touch_sample.person_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = pd.Series(index=touch_sample.index, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz = pd.Timedelta('00:00:01')\n",
    "for id_p in touch_sample_person_ids:\n",
    "    times = []\n",
    "    sample_one_id = touch_sample[touch_sample.person_id == id_p]\n",
    "    for idx, row in sample_one_id.iterrows():\n",
    "        this_time = row.touch_date\n",
    "        for t in times:\n",
    "            if np.abs(t-this_time) < fuzz:\n",
    "                to_delete.iloc[idx] = True\n",
    "                break\n",
    "        if not to_delete.iloc[idx]:\n",
    "            times.append(this_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch_sample_deduped = touch_sample[~to_delete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_user = touch_sample_deduped.person_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_user_hist = counts_by_user.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch.loc[10000].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch_person_ids = touch.person_id.unique()\n",
    "to_delete = pd.Series(index=touch.index, dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some type issue which makes me thing columns go misaligned somewhere in the file? This is strange. Will investigate later. The code below won't run until that's solved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz = pd.Timedelta('00:00:01')\n",
    "for id_p in touch_person_ids:\n",
    "    times = []\n",
    "    sample_one_id = touch[touch.person_id == id_p]\n",
    "    for idx, row in sample_one_id.iterrows():\n",
    "        this_time = row.touch_date\n",
    "        for t in times:\n",
    "            if np.abs(t-this_time) < fuzz:\n",
    "                to_delete.iloc[idx] = True\n",
    "                break\n",
    "        if not to_delete.iloc[idx]:\n",
    "            times.append(this_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
